<!DOCTYPE html>

<html>

  <head>
    <title>Ch. DRAFT - Imitation Learning</title>
    <meta name="Ch. DRAFT - Imitation Learning" content="text/html; charset=utf-8;" />
    <link rel="canonical" href="http://underactuated.mit.edu/imitation.html" />

    <script src="https://hypothes.is/embed.js" async></script>
    <script type="text/javascript" src="chapters.js"></script>
    <script type="text/javascript" src="htmlbook/book.js"></script>

    <script src="htmlbook/mathjax-config.js" defer></script>
    <script type="text/javascript" id="MathJax-script" defer
      src="htmlbook/MathJax/es5/tex-chtml.js">
    </script>
    <script>window.MathJax || document.write('<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" defer><\/script>')</script>

    <link rel="stylesheet" href="htmlbook/highlight/styles/default.css">
    <script src="htmlbook/highlight/highlight.pack.js"></script> <!-- http://highlightjs.readthedocs.io/en/latest/css-classes-reference.html#language-names-and-aliases -->
    <script>hljs.initHighlightingOnLoad();</script>

    <link rel="stylesheet" type="text/css" href="htmlbook/book.css" />
  </head>

<body onload="loadChapter('underactuated');">

<div data-type="titlepage">
  <header>
    <h1><a href="index.html" style="text-decoration:none;">Underactuated Robotics</a></h1>
    <p data-type="subtitle">Algorithms for Walking, Running, Swimming, Flying, and Manipulation</p>
    <p style="font-size: 18px;"><a href="http://people.csail.mit.edu/russt/">Russ Tedrake</a></p>
    <p style="font-size: 14px; text-align: right;">
      &copy; Russ Tedrake, 2023<br/>
      Last modified <span id="last_modified"></span>.</br>
      <script>
      var d = new Date(document.lastModified);
      document.getElementById("last_modified").innerHTML = d.getFullYear() + "-" + (d.getMonth()+1) + "-" + d.getDate();</script>
      <a href="misc.html">How to cite these notes, use annotations, and give feedback.</a><br/>
    </p>
  </header>
</div>

<p><b>Note:</b> These are working notes used for <a
href="https://underactuated.csail.mit.edu/Spring2023/">a course being taught
at MIT</a>. They will be updated throughout the Spring 2023 semester.  <a
href="https://www.youtube.com/channel/UChfUOAhz7ynELF-s_1LPpWg">Lecture videos are available on YouTube</a>.</p>

<table style="width:100%;"><tr style="width:100%">
  <td style="width:33%;text-align:left;"><a class="previous_chapter"></a></td>
  <td style="width:33%;text-align:center;"><a href=index.html>Table of contents</a></td>
  <td style="width:33%;text-align:right;"><a class="next_chapter"></a></td>
</tr></table>

<script type="text/javascript">document.write(notebook_header('imitation'))
</script>
<!-- EVERYTHING ABOVE THIS LINE IS OVERWRITTEN BY THE INSTALL SCRIPT -->
<chapter style="counter-reset: chapter 100"><h1>Imitation Learning</h1>

  <p>Two dominant approaches to imitation learning are <i>behavioral cloning</i> and <i>inverse reinforcement learning</i>...
  </p>

  <section><h1>Diffusion Policy</h1>
  
    <p>One particularly successful form of behavior cloning for visuomotor
    policies with continuous action spaces is the <a
    href="https://diffusion-policy.cs.columbia.edu/">Diffusion Policy</a>
    <elib>Chi23</elib>. The dexterous manipulation team at TRI had been working
    on behavior cloning for some time, but the Diffusion Policy (which started
    as a summer internship project!) architecture has allowed us to very
    reliably train <a
    href="https://www.youtube.com/watch?v=w-CGSQAO5-Q">incredibly dexterous
    tasks</a> and really start to scale up our ambitions for manipulation.</p>

    <subsection><h1>Score-matching diffusion</h1>
    
      <p>"Diffusion" models are an approach to generative AI which have
      principled foundations in statistics. The goal of a diffusion model is to
      model a probability distribution, but instead of estimating the
      probability density directly, we instead estimate the gradient of the log
      probability with respect to the random variable $\bx \in \Re^n$ (referred
      to in this literature as the "score function")<elib>Hyvarinen05</elib>.
      If $p(\bx; {\bf \theta})$ is a model probability density function over
      random vector variables $\bx$ parameterized by a vector ${\bf \theta},$
      then the score function we refer to here is $${\bf s}(\bx; {\bf \theta})
      = \pd{\log p(\bx; \theta)}{\bx},$$ which is a parameterized function from
      $\Re^n$ to $\Re^n.$</p>

      <p>Let's say that we obtain a dataset $\mathcal{D}$ of samples $\bx$.
      Denoting the probability density function on the data as
      $p_\mathcal{D}(\bx),$ and the score function of the data as ${\bf
      s}_\mathcal{D}(\bx)$, our goal is to find ${\bf \theta}$ which is the
      minimizer of $$\min_{\bf \theta} \frac{1}{2} \mathbb{E}_\mathcal{D}
      \left[ || {\bf s}(\bx; {\bf \theta}) - {\bf s}_\mathcal{D}(\bx)
      ||^2 \right].$$ <elib>Hyvarinen05</elib> showed that this objective is
      equivalent (up to a constant) to $$\mathbb{E}_\mathcal{D} \left[
      \tr\left(\pd{{\bf s}(\bx, {\bf \theta})}{\bx}\right) + \frac{1}{2} ||{\bf
      s}(\bx, {\bf \theta})||^2 \right].$$ The gradient in the first term is
      expensive to compute for deep networks, but <elib>Vincent11</elib>
      introduced "denoising score matching" which gets around this by
      perturbing all of the data with a pre-specified noise distribution,
      $q_\sigma(\tilde{\bx} | \bx),$ and optimizing the objective:
      $$\frac{1}{2}\mathbb{E}_\sigma \left[ \left|\left|{\bf s}(\tilde\bx; {\bf
      \theta}) - \pd{\log q_\sigma (\tilde\bx | \bx)}{\tilde\bx}
      \right|\right|^2 \right],$$ which they showed converges to the score
      function of the perturbed data distribution.</p>
    
      <todo>Simple examples implemented here.</todo>

      <p>The term "diffusion" came from a paper <elib>Sohl-Dickstein15</elib>
      which used an analogy from thermodynamics to use a prescribed diffusion
      process to slowly transform data into random noise, and then learned to
      reverse this procedure by training an inverse diffusion. 
      <elib>Song19</elib> put all of this together beautifully and combined it
      with deep learning to propose denoising diffusion as a generative
      modeling techinque. They learned a single network that was conditioned on
      the noise level. This was followed quickly by <elib>Ho20</elib> which
      showed results competitive with other leading generative modeling
      techniques and <elib>Song20</elib> introducing denoising diffusion
      implicit models (DDIM).</p>

      <todo>Examples! Something like Figure 1 from Sohl-Dickstein15 would be
      good.</todo>

    </subsection>

    <subsection><h1>Diffusion Policy</h1>

    </subsection>

    <subsection><h1>Diffusion Policy for LQG</h1>
    
      <p>Let me be clear, it almost certainly does <i>not</i> make sense to use
      a diffusion policy to implement LQG control. But because we understand
      LQG so well at this point, it can be helpful to understand what the
      Diffusion Policy looks like in this extremely simplified case.</p>

      <p>Consider the case where we have the standard linear-Gaussian dynamical
      system: \begin{gather*} \bx[n+1] = \bA\bx[n] + \bB\bu[n] + \bw[n], \\
      \by[n] = \bC\bx[n] + \bD\bu[n] + \bv[n], \\ \bw[n] \sim \mathcal{N}({\bf
      0}, {\bf \Sigma}_w), \quad \bv[n] \sim \mathcal{N}({\bf 0}, {\bf
      \Sigma}_v). \end{gather*} Imagine that we create a dataset by rolling out
      trajectory demonstrations using the optimal LQG policy. The question is:
      what (exactly) does the diffusion policy learn?</p>
    
    </subsection>
  
  </section>

</chapter>
<!-- EVERYTHING BELOW THIS LINE IS OVERWRITTEN BY THE INSTALL SCRIPT -->

<div id="references"><section><h1>References</h1>
<ol>

<li id=Chi23>
<span class="author">Cheng Chi and Siyuan Feng and Yilun Du and Zhenjia Xu and Eric Cousineau and Benjamin Burchfiel and Shuran Song</span>, 
<span class="title">"Diffusion Policy: Visuomotor Policy Learning via Action Diffusion"</span>, 
<span class="publisher">Proceedings of Robotics: Science and Systems</span> , <span class="year">2023</span>.

</li><br>
<li id=Hyvarinen05>
<span class="author">Aapo Hyvarinen</span>, 
<span class="title">"Estimation of {Non}-{Normalized} {Statistical} {Models} by {Score} {Matching}"</span>, 
<span class="publisher">Journal of Machine Learning Research</span>, vol. 6, pp. 695â€“708, <span class="year">2005</span>.

</li><br>
<li id=Vincent11>
<span class="author">Pascal Vincent</span>, 
<span class="title">"A connection between score matching and denoising autoencoders"</span>, 
<span class="publisher">Neural computation</span>, vol. 23, no. 7, pp. 1661--1674, <span class="year">2011</span>.

</li><br>
<li id=Sohl-Dickstein15>
<span class="author">Jascha Sohl-Dickstein and Eric Weiss and Niru Maheswaranathan and Surya Ganguli</span>, 
<span class="title">"Deep unsupervised learning using nonequilibrium thermodynamics"</span>, 
<span class="publisher">International conference on machine learning</span> , pp. 2256--2265, <span class="year">2015</span>.

</li><br>
<li id=Song19>
<span class="author">Yang Song and Stefano Ermon</span>, 
<span class="title">"Generative Modeling by Estimating Gradients of the Data Distribution"</span>, 
<span class="publisher">Advances in Neural Information Processing Systems</span> , vol. 32, <span class="year">2019</span>.

</li><br>
<li id=Ho20>
<span class="author">Jonathan Ho and Ajay Jain and Pieter Abbeel</span>, 
<span class="title">"Denoising diffusion probabilistic models"</span>, 
<span class="publisher">Advances in neural information processing systems</span>, vol. 33, pp. 6840--6851, <span class="year">2020</span>.

</li><br>
<li id=Song20>
<span class="author">Jiaming Song and Chenlin Meng and Stefano Ermon</span>, 
<span class="title">"Denoising Diffusion Implicit Models"</span>, 
<span class="publisher">International Conference on Learning Representations</span> , <span class="year">2020</span>.

</li><br>
</ol>
</section><p/>
</div>

<table style="width:100%;"><tr style="width:100%">
  <td style="width:33%;text-align:left;"><a class="previous_chapter"></a></td>
  <td style="width:33%;text-align:center;"><a href=index.html>Table of contents</a></td>
  <td style="width:33%;text-align:right;"><a class="next_chapter"></a></td>
</tr></table>

<div id="footer">
  <hr>
  <table style="width:100%;">
    <tr><td><a href="https://accessibility.mit.edu/">Accessibility</a></td><td style="text-align:right">&copy; Russ
      Tedrake, 2023</td></tr>
  </table>
</div>


</body>
</html>
